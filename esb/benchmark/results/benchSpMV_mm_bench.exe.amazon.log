Double-precision SpMV performance benchmark for 
 Intel(R) MKL SpMV Format Prototype Package, version 0.2
Input file: /tmp/amazon
Reading matrix completed
 cols[0]= 1, vals[0]=1.000000
 cols[1]= 2, vals[1]=1.000000
 cols[2]= 3, vals[2]=1.000000
 cols[3]= 4, vals[3]=1.000000
 cols[4]= 5, vals[4]=1.000000
 cols[5]= 0, vals[5]=1.000000
 cols[6]= 2, vals[6]=1.000000
 cols[7]= 13, vals[7]=1.000000
 cols[8]= 14, vals[8]=1.000000
 cols[9]= 15, vals[9]=1.000000
 cols[10]= 0, vals[10]=1.000000
 cols[11]= 1, vals[11]=1.000000
 cols[12]= 4, vals[12]=1.000000
 cols[13]= 5, vals[13]=1.000000
 cols[14]= 16, vals[14]=1.000000
 cols[15]= 70, vals[15]=1.000000
 cols[16]= 71, vals[16]=1.000000
 cols[17]= 72, vals[17]=1.000000
 cols[18]= 73, vals[18]=1.000000
 cols[19]= 74, vals[19]=1.000000
 cols[20]= 7, vals[20]=1.000000
 cols[21]= 17, vals[21]=1.000000
 cols[22]= 18, vals[22]=1.000000
 cols[23]= 19, vals[23]=1.000000
 cols[24]= 20, vals[24]=1.000000
 cols[25]= 6, vals[25]=1.000000
 cols[26]= 7, vals[26]=1.000000
 cols[27]= 8, vals[27]=1.000000
 cols[28]= 9, vals[28]=1.000000
 cols[29]= 10, vals[29]=1.000000
 cols[30]= 5, vals[30]=1.000000
 cols[31]= 7, vals[31]=1.000000
 cols[32]= 8, vals[32]=1.000000
 cols[33]= 9, vals[33]=1.000000
 cols[34]= 21, vals[34]=1.000000
 cols[35]= 5, vals[35]=1.000000
 cols[36]= 8, vals[36]=1.000000
 cols[37]= 9, vals[37]=1.000000
 cols[38]= 11, vals[38]=1.000000
 cols[39]= 12, vals[39]=1.000000
 cols[40]= 6, vals[40]=1.000000
 cols[41]= 11, vals[41]=1.000000
 cols[42]= 22, vals[42]=1.000000
 cols[43]= 23, vals[43]=1.000000
 cols[44]= 24, vals[44]=1.000000
 cols[45]= 5, vals[45]=1.000000
 cols[46]= 6, vals[46]=1.000000
 cols[47]= 7, vals[47]=1.000000
 cols[48]= 8, vals[48]=1.000000
 cols[49]= 11, vals[49]=1.000000
 cols[50]= 5, vals[50]=1.000000
 cols[51]= 7, vals[51]=1.000000
 cols[52]= 166, vals[52]=1.000000
 cols[53]= 167, vals[53]=1.000000
 cols[54]= 168, vals[54]=1.000000
 cols[55]= 8, vals[55]=1.000000
 cols[56]= 9, vals[56]=1.000000
 cols[57]= 25, vals[57]=1.000000
 cols[58]= 26, vals[58]=1.000000
 cols[59]= 27, vals[59]=1.000000
 cols[60]= 7, vals[60]=1.000000
 cols[61]= 8, vals[61]=1.000000
 cols[62]= 22, vals[62]=1.000000
 cols[63]= 28, vals[63]=1.000000
 cols[64]= 29, vals[64]=1.000000
 cols[65]= 1, vals[65]=1.000000
 cols[66]= 75, vals[66]=1.000000
 cols[67]= 76, vals[67]=1.000000
 cols[68]= 77, vals[68]=1.000000
 cols[69]= 78, vals[69]=1.000000
 cols[70]= 79, vals[70]=1.000000
 cols[71]= 299, vals[71]=1.000000
 cols[72]= 300, vals[72]=1.000000
 cols[73]= 301, vals[73]=1.000000
 cols[74]= 302, vals[74]=1.000000
 cols[75]= 303, vals[75]=1.000000
 cols[76]= 80, vals[76]=1.000000
 cols[77]= 81, vals[77]=1.000000
 cols[78]= 82, vals[78]=1.000000
 cols[79]= 83, vals[79]=1.000000
 cols[80]= 84, vals[80]=1.000000
 cols[81]= 4, vals[81]=1.000000
 cols[82]= 7, vals[82]=1.000000
 cols[83]= 20, vals[83]=1.000000
 cols[84]= 85, vals[84]=1.000000
 cols[85]= 87, vals[85]=1.000000
 cols[86]= 6, vals[86]=1.000000
 cols[87]= 7, vals[87]=1.000000
 cols[88]= 8, vals[88]=1.000000
 cols[89]= 11, vals[89]=1.000000
 cols[90]= 30, vals[90]=1.000000
 cols[91]= 31, vals[91]=1.000000
 cols[92]= 32, vals[92]=1.000000
 cols[93]= 33, vals[93]=1.000000
 cols[94]= 34, vals[94]=1.000000
 cols[95]= 35, vals[95]=1.000000
 cols[96]= 4, vals[96]=1.000000
 cols[97]= 17, vals[97]=1.000000
 cols[98]= 85, vals[98]=1.000000
 cols[99]= 86, vals[99]=1.000000
 cols[100]= 87, vals[100]=1.000000
 cols[101]= 6, vals[101]=1.000000
 cols[102]= 7, vals[102]=1.000000
 cols[103]= 8, vals[103]=1.000000
 cols[104]= 11, vals[104]=1.000000
 cols[105]= 304, vals[105]=1.000000
 cols[106]= 8, vals[106]=1.000000
 cols[107]= 11, vals[107]=1.000000
 cols[108]= 12, vals[108]=1.000000
 cols[109]= 21, vals[109]=1.000000
 cols[110]= 28, vals[110]=1.000000
 cols[111]= 211, vals[111]=1.000000
 cols[112]= 615, vals[112]=1.000000
 cols[113]= 1315, vals[113]=1.000000
 cols[114]= 2722, vals[114]=1.000000
 cols[115]= 3966, vals[115]=1.000000
 cols[116]= 6, vals[116]=1.000000
 cols[117]= 8, vals[117]=1.000000
 cols[118]= 36, vals[118]=1.000000
 cols[119]= 37, vals[119]=1.000000
 cols[120]= 38, vals[120]=1.000000
 cols[121]= 8, vals[121]=1.000000
 cols[122]= 39, vals[122]=1.000000
 cols[123]= 40, vals[123]=1.000000
 cols[124]= 41, vals[124]=1.000000
 cols[125]= 42, vals[125]=1.000000
 cols[126]= 11, vals[126]=1.000000
 cols[127]= 26, vals[127]=1.000000
 cols[128]= 305, vals[128]=1.000000
 cols[129]= 306, vals[129]=1.000000
 cols[130]= 307, vals[130]=1.000000
 cols[131]= 8, vals[131]=1.000000
 cols[132]= 11, vals[132]=1.000000
 cols[133]= 21, vals[133]=1.000000
 cols[134]= 25, vals[134]=1.000000
 cols[135]= 305, vals[135]=1.000000
 cols[136]= 306, vals[136]=1.000000
 cols[137]= 307, vals[137]=1.000000
 cols[138]= 422, vals[138]=1.000000
 cols[139]= 564, vals[139]=1.000000
 cols[140]= 615, vals[140]=1.000000
 cols[141]= 9, vals[141]=1.000000
 cols[142]= 11, vals[142]=1.000000
 cols[143]= 26, vals[143]=1.000000
 cols[144]= 88, vals[144]=1.000000
 cols[145]= 89, vals[145]=1.000000
 cols[146]= 7, vals[146]=1.000000
 cols[147]= 8, vals[147]=1.000000
 cols[148]= 12, vals[148]=1.000000
 cols[149]= 22, vals[149]=1.000000
 cols[150]= 29, vals[150]=1.000000
 cols[151]= 7, vals[151]=1.000000
 cols[152]= 12, vals[152]=1.000000
 cols[153]= 28, vals[153]=1.000000
 cols[154]= 211, vals[154]=1.000000
 cols[155]= 308, vals[155]=1.000000
 cols[156]= 9, vals[156]=1.000000
 cols[157]= 18, vals[157]=1.000000
 cols[158]= 90, vals[158]=1.000000
 cols[159]= 91, vals[159]=1.000000
 cols[160]= 92, vals[160]=1.000000
 cols[161]= 5, vals[161]=1.000000
 cols[162]= 19, vals[162]=1.000000
 cols[163]= 33, vals[163]=1.000000
 cols[164]= 43, vals[164]=1.000000
 cols[165]= 169, vals[165]=1.000000
 cols[166]= 48, vals[166]=1.000000
 cols[167]= 97, vals[167]=1.000000
 cols[168]= 98, vals[168]=1.000000
 cols[169]= 99, vals[169]=1.000000
 cols[170]= 139, vals[170]=1.000000
 cols[171]= 161, vals[171]=1.000000
 cols[172]= 203, vals[172]=1.000000
 cols[173]= 335, vals[173]=1.000000
 cols[174]= 636, vals[174]=1.000000
 cols[175]= 954, vals[175]=1.000000
 cols[176]= 19, vals[176]=1.000000
 cols[177]= 31, vals[177]=1.000000
 cols[178]= 43, vals[178]=1.000000
 cols[179]= 44, vals[179]=1.000000
 cols[180]= 45, vals[180]=1.000000
 cols[181]= 19, vals[181]=1.000000
 cols[182]= 32, vals[182]=1.000000
 cols[183]= 46, vals[183]=1.000000
 cols[184]= 47, vals[184]=1.000000
 cols[185]= 48, vals[185]=1.000000
 cols[186]= 19, vals[186]=1.000000
 cols[187]= 169, vals[187]=1.000000
 cols[188]= 170, vals[188]=1.000000
 cols[189]= 171, vals[189]=1.000000
 cols[190]= 172, vals[190]=1.000000
 cols[191]= 6, vals[191]=1.000000
 cols[192]= 8, vals[192]=1.000000
 cols[193]= 49, vals[193]=1.000000
 cols[194]= 50, vals[194]=1.000000
 cols[195]= 51, vals[195]=1.000000
 cols[196]= 23, vals[196]=1.000000
 cols[197]= 38, vals[197]=1.000000
 cols[198]= 40, vals[198]=1.000000
 cols[199]= 309, vals[199]=1.000000
 cols[200]= 310, vals[200]=1.000000
 cols[201]= 23, vals[201]=1.000000
 cols[202]= 52, vals[202]=1.000000
 cols[203]= 53, vals[203]=1.000000
 cols[204]= 54, vals[204]=1.000000
 cols[205]= 55, vals[205]=1.000000
 cols[206]= 24, vals[206]=1.000000
 cols[207]= 40, vals[207]=1.000000
 cols[208]= 41, vals[208]=1.000000
 cols[209]= 42, vals[209]=1.000000
 cols[210]= 93, vals[210]=1.000000
 cols[211]= 8, vals[211]=1.000000
 cols[212]= 24, vals[212]=1.000000
 cols[213]= 54, vals[213]=1.000000
 cols[214]= 311, vals[214]=1.000000
 cols[215]= 312, vals[215]=1.000000
 cols[216]= 24, vals[216]=1.000000
 cols[217]= 39, vals[217]=1.000000
 cols[218]= 42, vals[218]=1.000000
 cols[219]= 93, vals[219]=1.000000
 cols[220]= 94, vals[220]=1.000000
 cols[221]= 24, vals[221]=1.000000
 cols[222]= 39, vals[222]=1.000000
 cols[223]= 41, vals[223]=1.000000
 cols[224]= 93, vals[224]=1.000000
 cols[225]= 94, vals[225]=1.000000
 cols[226]= 19, vals[226]=1.000000
 cols[227]= 31, vals[227]=1.000000
 cols[228]= 33, vals[228]=1.000000
 cols[229]= 169, vals[229]=1.000000
 cols[230]= 313, vals[230]=1.000000
 cols[231]= 33, vals[231]=1.000000
 cols[232]= 314, vals[232]=1.000000
 cols[233]= 315, vals[233]=1.000000
 cols[234]= 316, vals[234]=1.000000
 cols[235]= 317, vals[235]=1.000000
 cols[236]= 34, vals[236]=1.000000
 cols[237]= 46, vals[237]=1.000000
 cols[238]= 56, vals[238]=1.000000
 cols[239]= 57, vals[239]=1.000000
 cols[240]= 58, vals[240]=1.000000
 cols[241]= 34, vals[241]=1.000000
 cols[242]= 45, vals[242]=1.000000
 cols[243]= 56, vals[243]=1.000000
 cols[244]= 91, vals[244]=1.000000
 cols[245]= 177, vals[245]=1.000000
 cols[246]= 34, vals[246]=1.000000
 cols[247]= 45, vals[247]=1.000000
 cols[248]= 46, vals[248]=1.000000
 cols[249]= 95, vals[249]=1.000000
 cols[250]= 96, vals[250]=1.000000
 cols[251]= 32, vals[251]=1.000000
 cols[252]= 97, vals[252]=1.000000
 cols[253]= 98, vals[253]=1.000000
 cols[254]= 99, vals[254]=1.000000
 cols[255]= 100, vals[255]=1.000000
Operation COO->CSR completed
Number of OMP threads: 240
Sparse matrix info:
       rows: 400727
       cols: 400727
       nnz:  3200440
Validation PASSED
MKL SpMV performance results:
   SpMV GFlop/s: 2.842373
   SpMV time:    0.002252
 y_ref[0] = 5.000000
 y_ref[16] = 5.000000
 y_ref[32] = 10.000000
 y_ref[48] = 5.000000
 y_ref[64] = 5.000000
 y_ref[80] = 5.000000
 y_ref[96] = 5.000000
 y_ref[112] = 5.000000
 y_ref[128] = 5.000000
 y_ref[144] = 5.000000
 y_ref[160] = 5.000000
 y_ref[176] = 5.000000
 y_ref[192] = 5.000000
 y_ref[208] = 5.000000
 y_ref[224] = 5.000000
 y_ref[240] = 5.000000
 before the end of MKL
Validation PASSED
CSR SpMV performance results:
   SpMV GFlop/s: 3.277803
   SpMV time:    0.001953
   schedule:     static
Validation PASSED
CSR SpMV performance results:
   SpMV GFlop/s: 3.556254
   SpMV time:    0.001800
   schedule:     dynamic
Validation PASSED
CSR SpMV performance results:
   SpMV GFlop/s: 2.569255
   SpMV time:    0.002491
   schedule:     block
Validation PASSED
ESB SpMV performance results:
   SpMV GFlop/s: 3.403044
   SpMV time:    0.001881
   schedule:     static
Validation PASSED
ESB SpMV performance results:
   SpMV GFlop/s: 3.619379
   SpMV time:    0.001769
   schedule:     dynamic
