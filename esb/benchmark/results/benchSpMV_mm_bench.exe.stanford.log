Double-precision SpMV performance benchmark for 
 Intel(R) MKL SpMV Format Prototype Package, version 0.2
Input file: /tmp/stanford
Reading matrix completed
 cols[0]= 6548, vals[0]=1.000000
 cols[1]= 15409, vals[1]=1.000000
 cols[2]= 17794, vals[2]=1.000000
 cols[3]= 25202, vals[3]=1.000000
 cols[4]= 53625, vals[4]=1.000000
 cols[5]= 54582, vals[5]=1.000000
 cols[6]= 64930, vals[6]=1.000000
 cols[7]= 73764, vals[7]=1.000000
 cols[8]= 84477, vals[8]=1.000000
 cols[9]= 98628, vals[9]=1.000000
 cols[10]= 100193, vals[10]=1.000000
 cols[11]= 102355, vals[11]=1.000000
 cols[12]= 105318, vals[12]=1.000000
 cols[13]= 105730, vals[13]=1.000000
 cols[14]= 115926, vals[14]=1.000000
 cols[15]= 140864, vals[15]=1.000000
 cols[16]= 163550, vals[16]=1.000000
 cols[17]= 164599, vals[17]=1.000000
 cols[18]= 175799, vals[18]=1.000000
 cols[19]= 178642, vals[19]=1.000000
 cols[20]= 181714, vals[20]=1.000000
 cols[21]= 190453, vals[21]=1.000000
 cols[22]= 204189, vals[22]=1.000000
 cols[23]= 204604, vals[23]=1.000000
 cols[24]= 210870, vals[24]=1.000000
 cols[25]= 213966, vals[25]=1.000000
 cols[26]= 225119, vals[26]=1.000000
 cols[27]= 241596, vals[27]=1.000000
 cols[28]= 243294, vals[28]=1.000000
 cols[29]= 246897, vals[29]=1.000000
 cols[30]= 251658, vals[30]=1.000000
 cols[31]= 252915, vals[31]=1.000000
 cols[32]= 280935, vals[32]=1.000000
 cols[33]= 74361, vals[33]=1.000000
 cols[34]= 35716, vals[34]=1.000000
 cols[35]= 96512, vals[35]=1.000000
 cols[36]= 186750, vals[36]=1.000000
 cols[37]= 225872, vals[37]=1.000000
 cols[38]= 6545, vals[38]=1.000000
 cols[39]= 14395, vals[39]=1.000000
 cols[40]= 59745, vals[40]=1.000000
 cols[41]= 67503, vals[41]=1.000000
 cols[42]= 134375, vals[42]=1.000000
 cols[43]= 170452, vals[43]=1.000000
 cols[44]= 220513, vals[44]=1.000000
 cols[45]= 6540, vals[45]=1.000000
 cols[46]= 59742, vals[46]=1.000000
 cols[47]= 45366, vals[47]=1.000000
 cols[48]= 123814, vals[48]=1.000000
 cols[49]= 149627, vals[49]=1.000000
 cols[50]= 194146, vals[50]=1.000000
 cols[51]= 198520, vals[51]=1.000000
 cols[52]= 240934, vals[52]=1.000000
 cols[53]= 35084, vals[53]=1.000000
 cols[54]= 41117, vals[54]=1.000000
 cols[55]= 58764, vals[55]=1.000000
 cols[56]= 86240, vals[56]=1.000000
 cols[57]= 222332, vals[57]=1.000000
 cols[58]= 248139, vals[58]=1.000000
 cols[59]= 270771, vals[59]=1.000000
 cols[60]= 32423, vals[60]=1.000000
 cols[61]= 6536, vals[61]=1.000000
 cols[62]= 55087, vals[62]=1.000000
 cols[63]= 118572, vals[63]=1.000000
 cols[64]= 149993, vals[64]=1.000000
 cols[65]= 68889, vals[65]=1.000000
 cols[66]= 95163, vals[66]=1.000000
 cols[67]= 136821, vals[67]=1.000000
 cols[68]= 251796, vals[68]=1.000000
 cols[69]= 272442, vals[69]=1.000000
 cols[70]= 41825, vals[70]=1.000000
 cols[71]= 76448, vals[71]=1.000000
 cols[72]= 180949, vals[72]=1.000000
 cols[73]= 34573, vals[73]=1.000000
 cols[74]= 38342, vals[74]=1.000000
 cols[75]= 81435, vals[75]=1.000000
 cols[76]= 105607, vals[76]=1.000000
 cols[77]= 167295, vals[77]=1.000000
 cols[78]= 198090, vals[78]=1.000000
 cols[79]= 214128, vals[79]=1.000000
 cols[80]= 226411, vals[80]=1.000000
 cols[81]= 234704, vals[81]=1.000000
 cols[82]= 245659, vals[82]=1.000000
 cols[83]= 214109, vals[83]=1.000000
 cols[84]= 19955, vals[84]=1.000000
 cols[85]= 25301, vals[85]=1.000000
 cols[86]= 61790, vals[86]=1.000000
 cols[87]= 65322, vals[87]=1.000000
 cols[88]= 101424, vals[88]=1.000000
 cols[89]= 234568, vals[89]=1.000000
 cols[90]= 24306, vals[90]=1.000000
 cols[91]= 34573, vals[91]=1.000000
 cols[92]= 38342, vals[92]=1.000000
 cols[93]= 41643, vals[93]=1.000000
 cols[94]= 52013, vals[94]=1.000000
 cols[95]= 52962, vals[95]=1.000000
 cols[96]= 54732, vals[96]=1.000000
 cols[97]= 55175, vals[97]=1.000000
 cols[98]= 57467, vals[98]=1.000000
 cols[99]= 66434, vals[99]=1.000000
 cols[100]= 81435, vals[100]=1.000000
 cols[101]= 94594, vals[101]=1.000000
 cols[102]= 105607, vals[102]=1.000000
 cols[103]= 129421, vals[103]=1.000000
 cols[104]= 141904, vals[104]=1.000000
 cols[105]= 142953, vals[105]=1.000000
 cols[106]= 150611, vals[106]=1.000000
 cols[107]= 166220, vals[107]=1.000000
 cols[108]= 167295, vals[108]=1.000000
 cols[109]= 180906, vals[109]=1.000000
 cols[110]= 186865, vals[110]=1.000000
 cols[111]= 190691, vals[111]=1.000000
 cols[112]= 192858, vals[112]=1.000000
 cols[113]= 198090, vals[113]=1.000000
 cols[114]= 200870, vals[114]=1.000000
 cols[115]= 203575, vals[115]=1.000000
 cols[116]= 214128, vals[116]=1.000000
 cols[117]= 223094, vals[117]=1.000000
 cols[118]= 226411, vals[118]=1.000000
 cols[119]= 230785, vals[119]=1.000000
 cols[120]= 231650, vals[120]=1.000000
 cols[121]= 234704, vals[121]=1.000000
 cols[122]= 244189, vals[122]=1.000000
 cols[123]= 245659, vals[123]=1.000000
 cols[124]= 271588, vals[124]=1.000000
 cols[125]= 280828, vals[125]=1.000000
 cols[126]= 13084, vals[126]=1.000000
 cols[127]= 72208, vals[127]=1.000000
 cols[128]= 2040, vals[128]=1.000000
 cols[129]= 23813, vals[129]=1.000000
 cols[130]= 111516, vals[130]=1.000000
 cols[131]= 130832, vals[131]=1.000000
 cols[132]= 168793, vals[132]=1.000000
 cols[133]= 170290, vals[133]=1.000000
 cols[134]= 185302, vals[134]=1.000000
 cols[135]= 186066, vals[135]=1.000000
 cols[136]= 193561, vals[136]=1.000000
 cols[137]= 226411, vals[137]=1.000000
 cols[138]= 231910, vals[138]=1.000000
 cols[139]= 236225, vals[139]=1.000000
 cols[140]= 239607, vals[140]=1.000000
 cols[141]= 244916, vals[141]=1.000000
 cols[142]= 251990, vals[142]=1.000000
 cols[143]= 277163, vals[143]=1.000000
 cols[144]= 277993, vals[144]=1.000000
 cols[145]= 2656, vals[145]=1.000000
 cols[146]= 9600, vals[146]=1.000000
 cols[147]= 36829, vals[147]=1.000000
 cols[148]= 146060, vals[148]=1.000000
 cols[149]= 175144, vals[149]=1.000000
 cols[150]= 195916, vals[150]=1.000000
 cols[151]= 141935, vals[151]=1.000000
 cols[152]= 186750, vals[152]=1.000000
 cols[153]= 197645, vals[153]=1.000000
 cols[154]= 203033, vals[154]=1.000000
 cols[155]= 222324, vals[155]=1.000000
 cols[156]= 225872, vals[156]=1.000000
 cols[157]= 266753, vals[157]=1.000000
 cols[158]= 6560, vals[158]=1.000000
 cols[159]= 15399, vals[159]=1.000000
 cols[160]= 67756, vals[160]=1.000000
 cols[161]= 69358, vals[161]=1.000000
 cols[162]= 148505, vals[162]=1.000000
 cols[163]= 241454, vals[163]=1.000000
 cols[164]= 145290, vals[164]=1.000000
 cols[165]= 220288, vals[165]=1.000000
 cols[166]= 37606, vals[166]=1.000000
 cols[167]= 72393, vals[167]=1.000000
 cols[168]= 109453, vals[168]=1.000000
 cols[169]= 121145, vals[169]=1.000000
 cols[170]= 186750, vals[170]=1.000000
 cols[171]= 206531, vals[171]=1.000000
 cols[172]= 208810, vals[172]=1.000000
 cols[173]= 225872, vals[173]=1.000000
 cols[174]= 229817, vals[174]=1.000000
 cols[175]= 271840, vals[175]=1.000000
 cols[176]= 7022, vals[176]=1.000000
 cols[177]= 9077, vals[177]=1.000000
 cols[178]= 17781, vals[178]=1.000000
 cols[179]= 38134, vals[179]=1.000000
 cols[180]= 62478, vals[180]=1.000000
 cols[181]= 66211, vals[181]=1.000000
 cols[182]= 71877, vals[182]=1.000000
 cols[183]= 75454, vals[183]=1.000000
 cols[184]= 77999, vals[184]=1.000000
 cols[185]= 96745, vals[185]=1.000000
 cols[186]= 104748, vals[186]=1.000000
 cols[187]= 120708, vals[187]=1.000000
 cols[188]= 120904, vals[188]=1.000000
 cols[189]= 127062, vals[189]=1.000000
 cols[190]= 137632, vals[190]=1.000000
 cols[191]= 138804, vals[191]=1.000000
 cols[192]= 145084, vals[192]=1.000000
 cols[193]= 176790, vals[193]=1.000000
 cols[194]= 177323, vals[194]=1.000000
 cols[195]= 181701, vals[195]=1.000000
 cols[196]= 183004, vals[196]=1.000000
 cols[197]= 183375, vals[197]=1.000000
 cols[198]= 200803, vals[198]=1.000000
 cols[199]= 207441, vals[199]=1.000000
 cols[200]= 221087, vals[200]=1.000000
 cols[201]= 247241, vals[201]=1.000000
 cols[202]= 255607, vals[202]=1.000000
 cols[203]= 259455, vals[203]=1.000000
 cols[204]= 273812, vals[204]=1.000000
 cols[205]= 14125, vals[205]=1.000000
 cols[206]= 19470, vals[206]=1.000000
 cols[207]= 20533, vals[207]=1.000000
 cols[208]= 53055, vals[208]=1.000000
 cols[209]= 84428, vals[209]=1.000000
 cols[210]= 92641, vals[210]=1.000000
 cols[211]= 116180, vals[211]=1.000000
 cols[212]= 117864, vals[212]=1.000000
 cols[213]= 141370, vals[213]=1.000000
 cols[214]= 165189, vals[214]=1.000000
 cols[215]= 177014, vals[215]=1.000000
 cols[216]= 226290, vals[216]=1.000000
 cols[217]= 243180, vals[217]=1.000000
 cols[218]= 244195, vals[218]=1.000000
 cols[219]= 247252, vals[219]=1.000000
 cols[220]= 281568, vals[220]=1.000000
 cols[221]= 6556, vals[221]=1.000000
 cols[222]= 31091, vals[222]=1.000000
 cols[223]= 34573, vals[223]=1.000000
 cols[224]= 38342, vals[224]=1.000000
 cols[225]= 81435, vals[225]=1.000000
 cols[226]= 105607, vals[226]=1.000000
 cols[227]= 167295, vals[227]=1.000000
 cols[228]= 198090, vals[228]=1.000000
 cols[229]= 214128, vals[229]=1.000000
 cols[230]= 226411, vals[230]=1.000000
 cols[231]= 234704, vals[231]=1.000000
 cols[232]= 245659, vals[232]=1.000000
 cols[233]= 6552, vals[233]=1.000000
 cols[234]= 15404, vals[234]=1.000000
 cols[235]= 6551, vals[235]=1.000000
 cols[236]= 19960, vals[236]=1.000000
 cols[237]= 28641, vals[237]=1.000000
 cols[238]= 142649, vals[238]=1.000000
 cols[239]= 245209, vals[239]=1.000000
 cols[240]= 25296, vals[240]=1.000000
 cols[241]= 237617, vals[241]=1.000000
 cols[242]= 244236, vals[242]=1.000000
 cols[243]= 6514, vals[243]=1.000000
 cols[244]= 118600, vals[244]=1.000000
 cols[245]= 7590, vals[245]=1.000000
 cols[246]= 140928, vals[246]=1.000000
 cols[247]= 149254, vals[247]=1.000000
 cols[248]= 177612, vals[248]=1.000000
 cols[249]= 183988, vals[249]=1.000000
 cols[250]= 204648, vals[250]=1.000000
 cols[251]= 6512, vals[251]=1.000000
 cols[252]= 95363, vals[252]=1.000000
 cols[253]= 257257, vals[253]=1.000000
 cols[254]= 33989, vals[254]=1.000000
 cols[255]= 78861, vals[255]=1.000000
Operation COO->CSR completed
Number of OMP threads: 240
Sparse matrix info:
       rows: 281903
       cols: 281903
       nnz:  2312497
Validation PASSED
MKL SpMV performance results:
   SpMV GFlop/s: 2.406675
   SpMV time:    0.001922
 y_ref[0] = 0.000000
 y_ref[16] = 6.000000
 y_ref[32] = 1.000000
 y_ref[48] = 4.000000
 y_ref[64] = 3.000000
 y_ref[80] = 7.000000
 y_ref[96] = 2.000000
 y_ref[112] = 5.000000
 y_ref[128] = 5.000000
 y_ref[144] = 86.000000
 y_ref[160] = 19.000000
 y_ref[176] = 1.000000
 y_ref[192] = 2.000000
 y_ref[208] = 3.000000
 y_ref[224] = 22.000000
 y_ref[240] = 6.000000
 before the end of MKL
Validation PASSED
CSR SpMV performance results:
   SpMV GFlop/s: 2.912181
   SpMV time:    0.001588
   schedule:     static
Validation PASSED
CSR SpMV performance results:
   SpMV GFlop/s: 2.886794
   SpMV time:    0.001602
   schedule:     dynamic
Validation PASSED
CSR SpMV performance results:
   SpMV GFlop/s: 2.448522
   SpMV time:    0.001889
   schedule:     block
Validation PASSED
ESB SpMV performance results:
   SpMV GFlop/s: 2.677314
   SpMV time:    0.001727
   schedule:     static
Validation PASSED
ESB SpMV performance results:
   SpMV GFlop/s: 2.643066
   SpMV time:    0.001750
   schedule:     dynamic
